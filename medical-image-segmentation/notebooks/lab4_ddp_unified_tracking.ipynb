{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Multi-GPU DDP Training with Unified Tracking\n",
    "\n",
    "## Overview\n",
    "Master Distributed Data Parallel (DDP) training with simultaneous tracking across TensorBoard, MLflow, and WandB. Learn when to use DDP vs FSDP and how to integrate multiple monitoring tools.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand DDP architecture and use cases\n",
    "- Configure multi-GPU training with PyTorch DDP\n",
    "- Integrate TensorBoard, MLflow, and WandB simultaneously\n",
    "- Compare DDP vs FSDP performance\n",
    "- Implement production-ready experiment tracking\n",
    "\n",
    "## Prerequisites\n",
    "- Completed Labs 1-3\n",
    "- MLflow server (optional)\n",
    "- WandB account\n",
    "\n",
    "**Estimated Time:** 60 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDP vs FSDP: When to Use What?\n",
    "\n",
    "### Distributed Data Parallel (DDP)\n",
    "```\n",
    "GPU 0: [Full Model] + [Batch 0]\n",
    "GPU 1: [Full Model] + [Batch 1]\n",
    "GPU 2: [Full Model] + [Batch 2]\n",
    "GPU 3: [Full Model] + [Batch 3]\n",
    "```\n",
    "\n",
    "### Fully Sharded Data Parallel (FSDP)\n",
    "```\n",
    "GPU 0: [Model Shard 0] + [Batch 0]\n",
    "GPU 1: [Model Shard 1] + [Batch 1]\n",
    "GPU 2: [Model Shard 2] + [Batch 2]\n",
    "GPU 3: [Model Shard 3] + [Batch 3]\n",
    "```\n",
    "\n",
    "### Decision Matrix\n",
    "\n",
    "| Scenario | Use DDP | Use FSDP |\n",
    "|----------|---------|----------|\n",
    "| Model fits in single GPU | âœ“ | âœ— |\n",
    "| Model > GPU memory | âœ— | âœ“ |\n",
    "| Parameters < 1B | âœ“ | âœ— |\n",
    "| Parameters > 1B | âœ— | âœ“ |\n",
    "| Need max speed | âœ“ | âœ— |\n",
    "| Need max memory | âœ— | âœ“ |\n",
    "\n",
    "**This Lab Uses DDP** because SegResNet/SwinUNETR fit in single GPU memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sagemaker==2.200.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session(boto3.Session(region_name='us-east-1'))\n",
    "# sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configure Tracking Tools\n",
    "\n",
    "Enable all three tracking systems for comprehensive monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "# TensorBoard (always enabled)\n",
    "use_tensorboard = True\n",
    "\n",
    "# MLflow (optional - requires server)\n",
    "use_mlflow = True\n",
    "mlflow_tracking_uri = \"\"  # e.g., \"http://mlflow.example.com:5000\"\n",
    "# Create an MLflow tracking server in SageMaker and provide its URI here\n",
    "# mlflow_tracking_uri = \"arn:aws:sagemaker:us-east-1:xxxx\"  # e.g., \"http://mlflow-server:5000\"\n",
    "mlflow_experiment_name = \"medical-seg-ddp-workshop\"\n",
    "\n",
    "# WandB (recommended)\n",
    "use_wandb = False\n",
    "wandb_api_key = getpass.getpass(\"Enter WandB API key (or press Enter to skip): \")\n",
    "wandb_project = \"medical-seg-ddp-workshop\"\n",
    "\n",
    "if not wandb_api_key:\n",
    "    use_wandb = False\n",
    "\n",
    "print(\"\\nðŸ“Š Tracking Configuration:\")\n",
    "print(f\"  TensorBoard: âœ“ Enabled\")\n",
    "print(f\"  MLflow: {'âœ“ Enabled' if use_mlflow else 'âœ— Disabled'}\")\n",
    "print(f\"  WandB: {'âœ“ Enabled' if use_wandb else 'âœ— Disabled'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'public-datasets-imaging-us-east-1'\n",
    "data_path = f's3://{bucket}/segmentation_data/'\n",
    "output_path = f's3://{bucket}/segmentation_data/output'\n",
    "\n",
    "print(f\"Training data: {data_path}\")\n",
    "print(f\"Output path: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Experiment 1 - 2 GPU Training\n",
    "\n",
    "Start with 2 GPUs to understand DDP basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_2gpu = {\n",
    "    \"model_name\": \"SegResNet\",\n",
    "    \"batch_size\": 4,  # Per GPU\n",
    "    \"epochs\": 15,\n",
    "    \"lr\": 1e-4,\n",
    "    \"use_mlflow\": str(use_mlflow),\n",
    "    \"use_wandb\": str(use_wandb),\n",
    "}\n",
    "\n",
    "if use_mlflow:\n",
    "    hyperparameters_2gpu[\"mlflow_tracking_uri\"] = mlflow_tracking_uri\n",
    "    hyperparameters_2gpu[\"mlflow_experiment_name\"] = mlflow_experiment_name\n",
    "\n",
    "if use_wandb:\n",
    "    hyperparameters_2gpu[\"wandb_project\"] = wandb_project\n",
    "    hyperparameters_2gpu[\"wandb_api_key\"] = wandb_api_key\n",
    "\n",
    "estimator_2gpu = PyTorch(\n",
    "    entry_point=\"train_ddp_all.py\",\n",
    "    source_dir=\"../code/training\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g4dn.12xlarge\",  # 2 GPUs\n",
    "    framework_version=\"2.1.0\",\n",
    "    py_version=\"py310\",\n",
    "    hyperparameters=hyperparameters_2gpu,\n",
    "    output_path=output_path,\n",
    "    base_job_name=\"ddp-2gpu-segresnet\",\n",
    "    keep_alive_period_in_seconds=1800,\n",
    "    distribution={\n",
    "        \"pytorchddp\": {\n",
    "            \"enabled\": True\n",
    "        },\n",
    "    },\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "print(\"âœ“ Experiment 1 configured: 2 GPU DDP\")\n",
    "print(f\"  Effective batch size: {hyperparameters_2gpu['batch_size'] * 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch training\n",
    "estimator_2gpu.fit({\"training\": data_path}, wait=True, logs=\"All\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Analyze Training Metrics\n",
    "\n",
    "Compare performance across tracking systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get training job details\n",
    "sm_client = boto3.client('sagemaker', region_name=region)\n",
    "\n",
    "jobs = [\n",
    "    estimator_2gpu.latest_training_job.name,\n",
    "]\n",
    "\n",
    "results = []\n",
    "for job_name in jobs:\n",
    "    job = sm_client.describe_training_job(TrainingJobName=job_name)\n",
    "    results.append({\n",
    "        \"Job\": job_name.split('-')[-3],\n",
    "        \"GPUs\": 2 if '4xlarge' in job['ResourceConfig']['InstanceType'] else 4,\n",
    "        \"Model\": job['HyperParameters']['model_name'],\n",
    "        \"Training Time (min)\": job['TrainingTimeInSeconds'] / 60,\n",
    "        \"Billable Time (min)\": job['BillableTimeInSeconds'] / 60,\n",
    "        \"Instance\": job['ResourceConfig']['InstanceType'],\n",
    "        \"Status\": job['TrainingJobStatus']\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(\"\\nðŸ“Š Training Job Comparison:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: View TensorBoard Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download TensorBoard logs from latest job\n",
    "latest_job = estimator_2gpu.latest_training_job.name\n",
    "model_data = estimator_2gpu.model_data\n",
    "\n",
    "!aws s3 cp {model_data} ./model.tar.gz\n",
    "!tar -xzf model.tar.gz\n",
    "\n",
    "print(\"\\nâœ“ TensorBoard logs downloaded\")\n",
    "print(\"\\nLaunch TensorBoard:\")\n",
    "print(\"  tensorboard --logdir=./\")\n",
    "print(\"\\nThen open: http://localhost:6006\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: View WandB Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_wandb:\n",
    "    import wandb\n",
    "    \n",
    "    wandb.login(key=wandb_api_key)\n",
    "    api = wandb.Api()\n",
    "    \n",
    "    runs = api.runs(f\"{api.default_entity}/{wandb_project}\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ WandB Dashboard:\")\n",
    "    print(f\"   https://wandb.ai/{api.default_entity}/{wandb_project}\")\n",
    "    print(f\"\\nðŸ“ˆ Found {len(runs)} runs\")\n",
    "    \n",
    "    for run in runs[:5]:\n",
    "        print(f\"\\n  Run: {run.name}\")\n",
    "        print(f\"    Model: {run.config.get('model_name')}\")\n",
    "        print(f\"    Best Dice: {run.summary.get('val/best_dice', 'N/A')}\")\n",
    "        print(f\"    Status: {run.state}\")\n",
    "else:\n",
    "    print(\"WandB not enabled. Set use_wandb=True to view dashboard.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: MLflow Tracking (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_mlflow:\n",
    "    import mlflow\n",
    "    \n",
    "    mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "    \n",
    "    # List experiments\n",
    "    experiments = mlflow.search_experiments()\n",
    "    \n",
    "    print(f\"\\nðŸ”¬ MLflow Experiments:\")\n",
    "    for exp in experiments:\n",
    "        if mlflow_experiment_name in exp.name:\n",
    "            print(f\"\\n  Experiment: {exp.name}\")\n",
    "            print(f\"    ID: {exp.experiment_id}\")\n",
    "            \n",
    "            # Get runs\n",
    "            runs = mlflow.search_runs(experiment_ids=[exp.experiment_id])\n",
    "            print(f\"    Runs: {len(runs)}\")\n",
    "            \n",
    "            if len(runs) > 0:\n",
    "                best_run = runs.loc[runs['metrics.best_dice'].idxmax()]\n",
    "                print(f\"\\n  Best Run:\")\n",
    "                print(f\"    Dice: {best_run['metrics.best_dice']:.4f}\")\n",
    "                print(f\"    Model: {best_run['params.model_name']}\")\n",
    "else:\n",
    "    print(\"MLflow not enabled. Set use_mlflow=True and configure server.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Calculate Scaling Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate speedup and efficiency\n",
    "if len(results) >= 2:\n",
    "    time_2gpu = results[0]['Training Time (min)']\n",
    "    time_4gpu = results[1]['Training Time (min)']\n",
    "    \n",
    "    speedup = time_2gpu / time_4gpu\n",
    "    efficiency = (speedup / 2) * 100  # 2x more GPUs\n",
    "    \n",
    "    print(\"\\nâš¡ Scaling Analysis:\")\n",
    "    print(f\"  2 GPU Time: {time_2gpu:.1f} min\")\n",
    "    print(f\"  4 GPU Time: {time_4gpu:.1f} min\")\n",
    "    print(f\"  Speedup: {speedup:.2f}x\")\n",
    "    print(f\"  Efficiency: {efficiency:.1f}%\")\n",
    "    print(f\"\\n  {'âœ“ Excellent' if efficiency > 85 else 'âš  Good' if efficiency > 70 else 'âœ— Poor'} scaling efficiency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding DDP Architecture\n",
    "\n",
    "### How DDP Works\n",
    "\n",
    "1. **Initialization**\n",
    "   - Each GPU gets full model copy\n",
    "   - Process group established (NCCL)\n",
    "   - Data distributed via DistributedSampler\n",
    "\n",
    "2. **Forward Pass**\n",
    "   - Each GPU processes its batch independently\n",
    "   - No communication between GPUs\n",
    "\n",
    "3. **Backward Pass**\n",
    "   - Gradients computed locally\n",
    "   - All-reduce operation synchronizes gradients\n",
    "   - Each GPU has identical gradients\n",
    "\n",
    "4. **Optimizer Step**\n",
    "   - Each GPU updates its model copy\n",
    "   - Models stay synchronized\n",
    "\n",
    "### Communication Patterns\n",
    "\n",
    "```\n",
    "Forward:  GPU0 â†’ GPU0  (no communication)\n",
    "          GPU1 â†’ GPU1\n",
    "          GPU2 â†’ GPU2\n",
    "          GPU3 â†’ GPU3\n",
    "\n",
    "Backward: GPU0 â†â†’ GPU1 â†â†’ GPU2 â†â†’ GPU3  (all-reduce)\n",
    "```\n",
    "\n",
    "### Memory Usage\n",
    "\n",
    "Per GPU:\n",
    "- Model parameters: ~5GB (SwinUNETR)\n",
    "- Gradients: ~5GB\n",
    "- Optimizer states: ~10GB\n",
    "- Activations: ~4GB (batch_size=2)\n",
    "- **Total: ~24GB** (fits in A10G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking System Comparison\n",
    "\n",
    "### TensorBoard\n",
    "âœ“ Built-in, no setup  \n",
    "âœ“ Local visualization  \n",
    "âœ“ Real-time updates  \n",
    "âœ— No cloud hosting  \n",
    "âœ— Limited collaboration  \n",
    "\n",
    "**Best for:** Quick local experiments\n",
    "\n",
    "### MLflow\n",
    "âœ“ Model registry  \n",
    "âœ“ Experiment comparison  \n",
    "âœ“ Self-hosted control  \n",
    "âœ— Requires server setup  \n",
    "âœ— Limited real-time features  \n",
    "\n",
    "**Best for:** Production ML pipelines\n",
    "\n",
    "### WandB\n",
    "âœ“ Cloud-hosted  \n",
    "âœ“ Real-time collaboration  \n",
    "âœ“ Advanced visualizations  \n",
    "âœ“ Hyperparameter sweeps  \n",
    "âœ— External dependency  \n",
    "\n",
    "**Best for:** Team collaboration and research\n",
    "\n",
    "### Recommendation\n",
    "Use **all three** for production:\n",
    "- TensorBoard: Quick debugging\n",
    "- MLflow: Model versioning\n",
    "- WandB: Team collaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "âœ“ **DDP Advantages:**\n",
    "- Faster than FSDP for models that fit in GPU\n",
    "- Simpler implementation\n",
    "- Better scaling efficiency (85-95%)\n",
    "- Lower communication overhead\n",
    "\n",
    "âœ“ **Multi-Tracking Benefits:**\n",
    "- TensorBoard for immediate feedback\n",
    "- MLflow for production tracking\n",
    "- WandB for team collaboration\n",
    "- Redundancy and flexibility\n",
    "\n",
    "âœ“ **Best Practices:**\n",
    "- Use DDP when model fits in single GPU\n",
    "- Batch size per GPU: 2-4 for medical imaging\n",
    "- Monitor GPU utilization (aim for >80%)\n",
    "- Enable gradient accumulation for larger effective batch sizes\n",
    "\n",
    "## Cost Analysis\n",
    "\n",
    "| Configuration | Instance | Time | Cost/Hour | Total Cost |\n",
    "|---------------|----------|------|-----------|------------|\n",
    "| 2 GPU DDP | ml.g5.4xlarge | 25 min | $2.83 | $1.18 |\n",
    "| 4 GPU DDP | ml.g5.12xlarge | 15 min | $7.09 | $1.77 |\n",
    "| **Difference** | | **-40%** | **+150%** | **+50%** |\n",
    "\n",
    "**Insight:** 4 GPUs cost 50% more but train 40% faster - good for production.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Implement gradient accumulation for larger batch sizes\n",
    "- Try mixed precision training (FP16)\n",
    "- Set up automated hyperparameter tuning\n",
    "- Deploy best model to SageMaker Endpoint\n",
    "- Create CI/CD pipeline with tracking integration\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [PyTorch DDP Tutorial](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)\n",
    "- [SageMaker Distributed Training](https://docs.aws.amazon.com/sagemaker/latest/dg/distributed-training.html)\n",
    "- [NCCL Performance Tuning](https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/usage/tuning.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg-jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
