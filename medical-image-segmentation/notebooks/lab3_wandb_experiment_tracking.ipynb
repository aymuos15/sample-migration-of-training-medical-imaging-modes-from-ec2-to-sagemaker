{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Experiment Tracking with WandB on SageMaker\n",
    "\n",
    "## Overview\n",
    "Learn how to integrate Weights & Biases (WandB) with SageMaker for advanced experiment tracking, visualization, and collaboration. This lab demonstrates multi-GPU training with comprehensive monitoring.\n",
    "\n",
    "## Learning Objectives\n",
    "- Set up WandB integration with SageMaker\n",
    "- Track experiments across multiple training runs\n",
    "- Visualize training metrics in real-time\n",
    "- Compare different model architectures and hyperparameters\n",
    "- Share results with team members\n",
    "\n",
    "## Prerequisites\n",
    "- Completed Lab 1 and Lab 2\n",
    "- WandB account (free tier available at wandb.ai)\n",
    "- WandB API key\n",
    "\n",
    "**Estimated Time:** 45-60 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Use WandB?\n",
    "\n",
    "| Feature | TensorBoard | MLflow | WandB |\n",
    "|---------|-------------|--------|-------|\n",
    "| Real-time Tracking | ‚úì | ‚úó | ‚úì |\n",
    "| Cloud Hosting | ‚úó | Self-hosted | ‚úì |\n",
    "| Collaboration | ‚úó | Limited | ‚úì |\n",
    "| Hyperparameter Sweeps | ‚úó | ‚úó | ‚úì |\n",
    "| Model Registry | ‚úó | ‚úì | ‚úì |\n",
    "| Artifacts Tracking | Limited | ‚úì | ‚úì |\n",
    "\n",
    "**Use WandB for:**\n",
    "- Team collaboration and sharing\n",
    "- Comparing multiple experiments\n",
    "- Hyperparameter optimization\n",
    "- Production model tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup WandB Account\n",
    "\n",
    "1. Go to https://wandb.ai/signup\n",
    "2. Create a free account\n",
    "3. Get your API key from https://wandb.ai/authorize\n",
    "4. Create a new project: \"medical-segmentation-workshop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store your WandB API key\n",
    "import getpass\n",
    "\n",
    "wandb_api_key = getpass.getpass(\"Enter your WandB API key: \")\n",
    "wandb_project = \"medical-segmentation-workshop\"\n",
    "\n",
    "print(f\"‚úì WandB configured for project: {wandb_project}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setup SageMaker Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_region_name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f's3://{bucket}/medical-imaging/data'\n",
    "output_path = f's3://{bucket}/medical-imaging/wandb-output'\n",
    "\n",
    "print(f\"Training Data: {data_path}\")\n",
    "print(f\"Output Path: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Experiment 1 - SegResNet Baseline\n",
    "\n",
    "Train a baseline model with SegResNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_segresnet = {\n",
    "    \"model_name\": \"SegResNet\",\n",
    "    \"batch_size\": 4,\n",
    "    \"epochs\": 20,\n",
    "    \"lr\": 1e-4,\n",
    "    \"use_wandb\": True,\n",
    "    \"use_mlflow\": False,\n",
    "    \"wandb_project\": wandb_project,\n",
    "    \"wandb_api_key\": wandb_api_key\n",
    "}\n",
    "\n",
    "estimator_segresnet = PyTorch(\n",
    "    entry_point=\"train_ddp_all.py\",\n",
    "    source_dir=\"../code\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",  # 1 GPU\n",
    "    framework_version=\"2.5.1\",\n",
    "    py_version=\"py311\",\n",
    "    hyperparameters=hyperparameters_segresnet,\n",
    "    output_path=output_path,\n",
    "    base_job_name=\"segresnet-baseline\",\n",
    "    keep_alive_period_in_seconds=1800\n",
    ")\n",
    "\n",
    "print(\"‚úì Experiment 1: SegResNet Baseline configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch training\n",
    "estimator_segresnet.fit({\"training\": data_path}, wait=True, logs=\"All\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Experiment 2 - SwinUNETR with Higher Learning Rate\n",
    "\n",
    "Test a larger model with different hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_swin = {\n",
    "    \"model_name\": \"SwinUNETR\",\n",
    "    \"batch_size\": 2,\n",
    "    \"epochs\": 20,\n",
    "    \"lr\": 5e-4,  # Higher learning rate\n",
    "    \"use_wandb\": True,\n",
    "    \"use_mlflow\": False,\n",
    "    \"wandb_project\": wandb_project,\n",
    "    \"wandb_api_key\": wandb_api_key\n",
    "}\n",
    "\n",
    "estimator_swin = PyTorch(\n",
    "    entry_point=\"train_ddp_all.py\",\n",
    "    source_dir=\"../code\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    framework_version=\"2.5.1\",\n",
    "    py_version=\"py311\",\n",
    "    hyperparameters=hyperparameters_swin,\n",
    "    output_path=output_path,\n",
    "    base_job_name=\"swinunetr-high-lr\",\n",
    "    keep_alive_period_in_seconds=1800\n",
    ")\n",
    "\n",
    "print(\"‚úì Experiment 2: SwinUNETR configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch training\n",
    "estimator_swin.fit({\"training\": data_path}, wait=True, logs=\"All\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Experiment 3 - Multi-GPU Training\n",
    "\n",
    "Scale to 4 GPUs with DDP for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_multigpu = {\n",
    "    \"model_name\": \"SwinUNETR\",\n",
    "    \"batch_size\": 2,\n",
    "    \"epochs\": 20,\n",
    "    \"lr\": 1e-4,\n",
    "    \"use_wandb\": True,\n",
    "    \"use_mlflow\": False,\n",
    "    \"wandb_project\": wandb_project,\n",
    "    \"wandb_api_key\": wandb_api_key\n",
    "}\n",
    "\n",
    "estimator_multigpu = PyTorch(\n",
    "    entry_point=\"train_ddp_all.py\",\n",
    "    source_dir=\"../code\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g5.12xlarge\",  # 4 GPUs\n",
    "    framework_version=\"2.5.1\",\n",
    "    py_version=\"py311\",\n",
    "    hyperparameters=hyperparameters_multigpu,\n",
    "    output_path=output_path,\n",
    "    base_job_name=\"swinunetr-4gpu\",\n",
    "    keep_alive_period_in_seconds=1800,\n",
    "    distribution={\n",
    "        \"pytorchddp\": {\n",
    "            \"enabled\": True\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"‚úì Experiment 3: Multi-GPU DDP configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch training\n",
    "estimator_multigpu.fit({\"training\": data_path}, wait=True, logs=\"All\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Analyze Results in WandB\n",
    "\n",
    "View and compare all experiments in WandB dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# Login to WandB\n",
    "wandb.login(key=wandb_api_key)\n",
    "\n",
    "# Get project URL\n",
    "project_url = f\"https://wandb.ai/{wandb.api.default_entity}/{wandb_project}\"\n",
    "print(f\"\\nüéØ View your experiments:\")\n",
    "print(f\"   {project_url}\")\n",
    "print(f\"\\nüìä Compare runs:\")\n",
    "print(f\"   {project_url}/table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Programmatic Analysis with WandB API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Fetch runs from WandB\n",
    "api = wandb.Api()\n",
    "runs = api.runs(f\"{wandb.api.default_entity}/{wandb_project}\")\n",
    "\n",
    "# Create comparison table\n",
    "summary_list = []\n",
    "for run in runs:\n",
    "    summary_list.append({\n",
    "        \"name\": run.name,\n",
    "        \"model\": run.config.get(\"model_name\"),\n",
    "        \"batch_size\": run.config.get(\"batch_size\"),\n",
    "        \"lr\": run.config.get(\"lr\"),\n",
    "        \"best_dice\": run.summary.get(\"val/best_dice\", 0),\n",
    "        \"duration\": run.summary.get(\"_runtime\", 0) / 60,  # minutes\n",
    "        \"state\": run.state\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(summary_list)\n",
    "df = df.sort_values(\"best_dice\", ascending=False)\n",
    "\n",
    "print(\"\\nüìà Experiment Comparison:\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_run = df.iloc[0]\n",
    "print(f\"\\nüèÜ Best Model:\")\n",
    "print(f\"   Name: {best_run['name']}\")\n",
    "print(f\"   Model: {best_run['model']}\")\n",
    "print(f\"   Dice Score: {best_run['best_dice']:.4f}\")\n",
    "print(f\"   Training Time: {best_run['duration']:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Download Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best run details\n",
    "best_run_name = df.iloc[0]['name']\n",
    "best_run_obj = [r for r in runs if r.name == best_run_name][0]\n",
    "\n",
    "# Download artifacts\n",
    "print(f\"Downloading artifacts from: {best_run_name}\")\n",
    "for artifact in best_run_obj.logged_artifacts():\n",
    "    artifact.download()\n",
    "    print(f\"  ‚úì Downloaded: {artifact.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WandB Features Demonstrated\n",
    "\n",
    "### 1. Real-time Monitoring\n",
    "- Live training metrics\n",
    "- GPU utilization\n",
    "- System metrics (CPU, memory)\n",
    "\n",
    "### 2. Experiment Comparison\n",
    "- Side-by-side metric plots\n",
    "- Hyperparameter correlation\n",
    "- Performance tables\n",
    "\n",
    "### 3. Collaboration\n",
    "- Share project links with team\n",
    "- Comment on runs\n",
    "- Create reports\n",
    "\n",
    "### 4. Artifact Tracking\n",
    "- Model checkpoints\n",
    "- Training logs\n",
    "- Predictions and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "‚úì **WandB Benefits:**\n",
    "- Zero-setup cloud hosting\n",
    "- Real-time collaboration\n",
    "- Comprehensive experiment tracking\n",
    "- Easy hyperparameter comparison\n",
    "\n",
    "‚úì **Best Practices:**\n",
    "- Tag runs with meaningful names\n",
    "- Use groups for related experiments\n",
    "- Log custom metrics and artifacts\n",
    "- Create reports for stakeholders\n",
    "\n",
    "‚úì **Integration Tips:**\n",
    "- Store API key in AWS Secrets Manager\n",
    "- Use WandB sweeps for hyperparameter tuning\n",
    "- Enable artifact versioning\n",
    "- Set up alerts for failed runs\n",
    "\n",
    "## Cost Analysis\n",
    "\n",
    "| Experiment | Instance | Duration | Cost |\n",
    "|------------|----------|----------|------|\n",
    "| SegResNet | ml.g5.2xlarge | 30 min | $1.41 |\n",
    "| SwinUNETR | ml.g5.2xlarge | 45 min | $2.11 |\n",
    "| Multi-GPU | ml.g5.12xlarge | 20 min | $2.36 |\n",
    "| **Total** | | | **$5.88** |\n",
    "\n",
    "**WandB Cost:** Free tier (100GB storage, unlimited runs)\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Set up automated hyperparameter sweeps\n",
    "- Deploy best model to SageMaker Endpoint\n",
    "- Create WandB reports for stakeholders\n",
    "- Integrate with CI/CD pipeline\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [WandB Documentation](https://docs.wandb.ai/)\n",
    "- [SageMaker + WandB Guide](https://docs.wandb.ai/guides/integrations/sagemaker)\n",
    "- [Hyperparameter Sweeps](https://docs.wandb.ai/guides/sweeps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
