{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FSDP Multi-GPU Training on SageMaker\n",
    "\n",
    "Train medical image segmentation models with Fully Sharded Data Parallel (FSDP) across multiple GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ubuntu/.config/sagemaker/config.yaml\n",
      "Region: us-east-1\n",
      "Bucket: sagemaker-us-east-1-575108919340\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session(boto3.Session(region_name='us-east-1'))\n",
    "\n",
    "\n",
    "\n",
    "# sagemaker_session = sagemaker.Session()\n",
    "# role = get_execution_role()\n",
    "role=\"AmazonSageMaker-ExecutionRole-20240907T181142\"\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Path\n",
    "\n",
    "Point to your S3 data location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: s3://public-datasets-imaging-us-east-1/segmentation_data/\n",
      "Output path: s3://public-datasets-imaging-us-east-1/segmentation_data/output\n"
     ]
    }
   ],
   "source": [
    "bucket = 'public-datasets-imaging-us-east-1'\n",
    "data_path = f's3://{bucket}/segmentation_data/'\n",
    "output_path = f's3://{bucket}/segmentation_data/output'\n",
    "\n",
    "print(f\"Training data: {data_path}\")\n",
    "print(f\"Output path: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator configured successfully\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "hyperparameters = {\n",
    "    'model_name': 'SegResNet',\n",
    "    'batch_size': 2,\n",
    "    'epochs': 10,\n",
    "    'lr': 0.0001\n",
    "}\n",
    "\n",
    "# PyTorch Estimator with FSDP\n",
    "estimator = PyTorch(\n",
    "    entry_point='train_fsdp.py',\n",
    "    source_dir='../code/training',\n",
    "    role=role,\n",
    "    instance_type='ml.g4dn.12xlarge',  # 4 GPUs\n",
    "    instance_count=1,\n",
    "    framework_version='2.0.0',\n",
    "    py_version='py310',\n",
    "    hyperparameters=hyperparameters,\n",
    "    distribution={\n",
    "        'pytorchddp': {\n",
    "            'enabled': True\n",
    "        }\n",
    "    },\n",
    "    keep_alive_period_in_seconds=600,\n",
    "    disable_profiler=True,\n",
    "    debugger_hook_config=False,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "print(\"Estimator configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2026-01-25-20-44-53-697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-25 20:44:54 Starting - Starting the training job...\n",
      "2026-01-25 20:45:23 Pending - Training job waiting for capacity...\n",
      "2026-01-25 20:45:48 Pending - Preparing the instances for training...\n",
      "2026-01-25 20:46:17 Downloading - Downloading input data...\n",
      "2026-01-25 20:46:42 Downloading - Downloading the training image..................\n",
      "2026-01-25 20:49:54 Training - Training image download completed. Training in progress.......bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2026-01-25 20:50:45,759 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2026-01-25 20:50:45,794 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2026-01-25 20:50:45,803 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2026-01-25 20:50:45,805 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel for native PT DDP job\n",
      "2026-01-25 20:50:45,805 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2026-01-25 20:50:47,240 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/opt/conda/bin/python3.10 -m pip install -r requirements.txt\n",
      "Collecting monai==1.3.2 (from -r requirements.txt (line 1))\n",
      "Downloading monai-1.3.2-py3-none-any.whl (1.4 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 41.3 MB/s eta 0:00:00\n",
      "Collecting torch==2.4.1 (from -r requirements.txt (line 2))\n",
      "Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 797.1/797.1 MB 1.5 MB/s eta 0:00:00\n",
      "Collecting numpy==1.26.4 (from -r requirements.txt (line 3))\n",
      "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 80.0 MB/s eta 0:00:00\n",
      "Collecting natsort (from -r requirements.txt (line 4))\n",
      "Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.6.1)\n",
      "Collecting tensorboard (from -r requirements.txt (line 6))\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 77.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (4.65.0)\n",
      "Collecting wandb (from -r requirements.txt (line 8))\n",
      "Downloading wandb-0.24.0-py3-none-manylinux_2_28_x86_64.whl (22.8 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 22.8/22.8 MB 51.6 MB/s eta 0:00:00\n",
      "Collecting mlflow (from -r requirements.txt (line 9))\n",
      "Downloading mlflow-3.8.1-py3-none-any.whl (9.1 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.1/9.1 MB 92.7 MB/s eta 0:00:00\n",
      "Collecting SimpleITK (from -r requirements.txt (line 10))\n",
      "Downloading simpleitk-2.5.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (52.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.6/52.6 MB 40.1 MB/s eta 0:00:00\n",
      "Collecting nibabel (from -r requirements.txt (line 11))\n",
      "Downloading nibabel-5.3.3-py3-none-any.whl (3.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 158.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (2.172.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->-r requirements.txt (line 2)) (3.12.2)\n",
      "Collecting typing-extensions>=4.8.0 (from torch==2.4.1->-r requirements.txt (line 2))\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.6/44.6 kB 19.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->-r requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->-r requirements.txt (line 2)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->-r requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1->-r requirements.txt (line 2)) (2023.6.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1->-r requirements.txt (line 2))\n",
      "Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 58.8 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1->-r requirements.txt (line 2))\n",
      "Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.6/823.6 kB 122.9 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1->-r requirements.txt (line 2))\n",
      "Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 49.3 MB/s eta 0:00:00\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1->-r requirements.txt (line 2))\n",
      "Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 1.9 MB/s eta 0:00:00\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1->-r requirements.txt (line 2))\n",
      "Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.6/410.6 MB 3.1 MB/s eta 0:00:00\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1->-r requirements.txt (line 2))\n",
      "Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.6/121.6 MB 21.2 MB/s eta 0:00:00\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1->-r requirements.txt (line 2))\n",
      "Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.5/56.5 MB 42.1 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1->-r requirements.txt (line 2))\n",
      "Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.2/124.2 MB 23.1 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1->-r requirements.txt (line 2))\n",
      "Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.0/196.0 MB 10.5 MB/s eta 0:00:00\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1->-r requirements.txt (line 2))\n",
      "Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 176.2/176.2 MB 12.8 MB/s eta 0:00:00\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1->-r requirements.txt (line 2))\n",
      "Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 99.1/99.1 kB 41.5 MB/s eta 0:00:00\n",
      "Collecting triton==3.0.0 (from torch==2.4.1->-r requirements.txt (line 2))\n",
      "Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.4/209.4 MB 9.2 MB/s eta 0:00:00\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1->-r requirements.txt (line 2))\n",
      "Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.7/39.7 MB 51.7 MB/s eta 0:00:00\n",
      "Collecting absl-py>=0.4 (from tensorboard->-r requirements.txt (line 6))\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.8/135.8 kB 51.7 MB/s eta 0:00:00\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->-r requirements.txt (line 6))\n",
      "Downloading grpcio-1.76.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 93.5 MB/s eta 0:00:00\n",
      "Collecting markdown>=2.6.8 (from tensorboard->-r requirements.txt (line 6))\n",
      "Downloading markdown-3.10.1-py3-none-any.whl (107 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 107.7/107.7 kB 45.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 6)) (23.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 6)) (10.0.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 6)) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 6)) (65.6.3)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r requirements.txt (line 6))\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 147.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 6)) (2.3.6)\n",
      "Requirement already satisfied: click>=8.0.1 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 8)) (8.1.4)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 8))\n",
      "Downloading gitpython-3.1.46-py3-none-any.whl (208 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 208.6/208.6 kB 64.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 8)) (3.8.1)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 8)) (1.10.11)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 8)) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 8)) (2.31.0)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb->-r requirements.txt (line 8))\n",
      "Downloading sentry_sdk-2.50.0-py2.py3-none-any.whl (424 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 425.0/425.0 kB 97.8 MB/s eta 0:00:00\n",
      "Collecting mlflow-skinny==3.8.1 (from mlflow->-r requirements.txt (line 9))\n",
      "Downloading mlflow_skinny-3.8.1-py3-none-any.whl (2.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 97.4 MB/s eta 0:00:00\n",
      "Collecting mlflow-tracing==3.8.1 (from mlflow->-r requirements.txt (line 9))\n",
      "Downloading mlflow_tracing-3.8.1-py3-none-any.whl (1.4 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 117.8 MB/s eta 0:00:00\n",
      "Collecting Flask-CORS<7 (from mlflow->-r requirements.txt (line 9))\n",
      "Downloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\n",
      "Collecting Flask<4 (from mlflow->-r requirements.txt (line 9))\n",
      "Downloading flask-3.1.2-py3-none-any.whl (103 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.3/103.3 kB 43.8 MB/s eta 0:00:00\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow->-r requirements.txt (line 9))\n",
      "Downloading alembic-1.18.1-py3-none-any.whl (260 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 261.0/261.0 kB 70.6 MB/s eta 0:00:00\n",
      "Collecting cryptography<47,>=43.0.0 (from mlflow->-r requirements.txt (line 9))\n",
      "Downloading cryptography-46.0.3-cp38-abi3-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 131.1 MB/s eta 0:00:00\n",
      "Collecting docker<8,>=4.0.0 (from mlflow->-r requirements.txt (line 9))\n",
      "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 147.8/147.8 kB 56.1 MB/s eta 0:00:00\n",
      "Collecting graphene<4 (from mlflow->-r requirements.txt (line 9))\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.9/114.9 kB 46.1 MB/s eta 0:00:00\n",
      "Collecting gunicorn<24 (from mlflow->-r requirements.txt (line 9))\n",
      "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.0/85.0 kB 35.6 MB/s eta 0:00:00\n",
      "Collecting huey<3,>=2.5.0 (from mlflow->-r requirements.txt (line 9))\n",
      "Downloading huey-2.6.0-py3-none-any.whl (76 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.0/77.0 kB 30.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.10/site-packages (from mlflow->-r requirements.txt (line 9)) (3.7.2)\n",
      "Requirement already satisfied: pandas<3 in /opt/conda/lib/python3.10/site-packages (from mlflow->-r requirements.txt (line 9)) (2.0.3)\n",
      "Requirement already satisfied: pyarrow<23,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow->-r requirements.txt (line 9)) (12.0.1)\n",
      "Requirement already satisfied: scikit-learn<2 in /opt/conda/lib/python3.10/site-packages (from mlflow->-r requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: scipy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow->-r requirements.txt (line 9)) (1.11.1)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow->-r requirements.txt (line 9))\n",
      "Downloading sqlalchemy-2.0.46-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 111.3 MB/s eta 0:00:00\n",
      "Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading cachetools-6.2.5-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: cloudpickle<4 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9)) (2.2.1)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading databricks_sdk-0.80.0-py3-none-any.whl (788 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 788.3/788.3 kB 84.7 MB/s eta 0:00:00\n",
      "Collecting fastapi<1 (from mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading fastapi-0.128.0-py3-none-any.whl (103 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.1/103.1 kB 43.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9)) (6.8.0)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.4/66.4 kB 29.2 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.5/72.5 kB 33.4 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.6/132.6 kB 50.3 MB/s eta 0:00:00\n",
      "Collecting pydantic<3 (from wandb->-r requirements.txt (line 8))\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 463.6/463.6 kB 87.7 MB/s eta 0:00:00\n",
      "Collecting python-dotenv<2,>=0.19.0 (from mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading sqlparse-0.5.5-py3-none-any.whl (46 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.1/46.1 kB 21.1 MB/s eta 0:00:00\n",
      "Collecting uvicorn<1 (from mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading uvicorn-0.40.0-py3-none-any.whl (68 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 68.5/68.5 kB 27.5 MB/s eta 0:00:00\n",
      "Collecting importlib-resources>=5.12 (from nibabel->-r requirements.txt (line 11))\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 12)) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 12)) (1.28.2)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 12)) (1.0.1)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 12)) (0.3.0)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 12)) (0.7.5)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 12)) (4.18.3)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 12)) (1.7.0)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow->-r requirements.txt (line 9))\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 34.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tomli in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow->-r requirements.txt (line 9)) (2.0.1)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.2 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker->-r requirements.txt (line 12)) (1.31.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker->-r requirements.txt (line 12)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker->-r requirements.txt (line 12)) (0.6.1)\n",
      "Collecting cffi>=2.0.0 (from cryptography<47,>=43.0.0->mlflow->-r requirements.txt (line 9))\n",
      "Downloading cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 216.5/216.5 kB 62.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow->-r requirements.txt (line 9)) (1.26.15)\n",
      "Collecting blinker>=1.9.0 (from Flask<4->mlflow->-r requirements.txt (line 9))\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from Flask<4->mlflow->-r requirements.txt (line 9))\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow->-r requirements.txt (line 9)) (2.1.3)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard->-r requirements.txt (line 6))\n",
      "Downloading werkzeug-3.1.5-py3-none-any.whl (225 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 225.0/225.0 kB 71.0 MB/s eta 0:00:00\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 8))\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.8/62.8 kB 28.4 MB/s eta 0:00:00\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow->-r requirements.txt (line 9))\n",
      "Downloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.3/207.3 kB 63.2 MB/s eta 0:00:00\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow->-r requirements.txt (line 9))\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from graphene<4->mlflow->-r requirements.txt (line 9)) (2.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9)) (3.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow->-r requirements.txt (line 9)) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow->-r requirements.txt (line 9)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow->-r requirements.txt (line 9)) (4.41.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow->-r requirements.txt (line 9)) (1.4.4)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow->-r requirements.txt (line 9)) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3->mlflow->-r requirements.txt (line 9)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3->mlflow->-r requirements.txt (line 9)) (2023.3)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->wandb->-r requirements.txt (line 8))\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3->wandb->-r requirements.txt (line 8))\n",
      "Downloading pydantic_core-2.41.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 107.0 MB/s eta 0:00:00\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3->wandb->-r requirements.txt (line 8))\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 8)) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 8)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 8)) (2023.5.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow->-r requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow->-r requirements.txt (line 9)) (3.2.0)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow->-r requirements.txt (line 9)) (2.0.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from google-pasta->sagemaker->-r requirements.txt (line 12)) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker->-r requirements.txt (line 12)) (2023.6.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker->-r requirements.txt (line 12)) (0.29.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker->-r requirements.txt (line 12)) (0.8.10)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker->-r requirements.txt (line 12)) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker->-r requirements.txt (line 12)) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker->-r requirements.txt (line 12)) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker->-r requirements.txt (line 12)) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.10/site-packages (from schema->sagemaker->-r requirements.txt (line 12)) (21.6.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.4.1->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=2.0.0->cryptography<47,>=43.0.0->mlflow->-r requirements.txt (line 9)) (2.21)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading google_auth-2.47.0-py3-none-any.whl (234 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 234.9/234.9 kB 71.1 MB/s eta 0:00:00\n",
      "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard->-r requirements.txt (line 6))\n",
      "Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 294.9/294.9 kB 77.3 MB/s eta 0:00:00\n",
      "Collecting starlette<0.51.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 74.0/74.0 kB 30.3 MB/s eta 0:00:00\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi<1->mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 8))\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading opentelemetry_proto-1.39.0-py3-none-any.whl (72 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.5/72.5 kB 32.0 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.5/72.5 kB 32.5 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.5/72.5 kB 32.4 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.5/72.5 kB 31.2 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_proto-1.35.0-py3-none-any.whl (72 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.5/72.5 kB 31.2 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.7/55.7 kB 26.3 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_proto-1.34.0-py3-none-any.whl (55 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.7/55.7 kB 25.2 MB/s eta 0:00:00\n",
      "INFO: pip is looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\n",
      "Downloading opentelemetry_proto-1.33.1-py3-none-any.whl (55 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.9/55.9 kB 25.1 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_proto-1.33.0-py3-none-any.whl (55 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.9/55.9 kB 25.7 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.9/55.9 kB 25.5 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_proto-1.32.0-py3-none-any.whl (55 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.9/55.9 kB 26.5 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_proto-1.31.1-py3-none-any.whl (55 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.9/55.9 kB 25.2 MB/s eta 0:00:00\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Downloading opentelemetry_proto-1.31.0-py3-none-any.whl (55 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.9/55.9 kB 24.1 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.9/55.9 kB 22.9 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.8/55.8 kB 25.1 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_proto-1.28.2-py3-none-any.whl (55 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.8/55.8 kB 26.8 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_proto-1.28.1-py3-none-any.whl (55 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.8/55.8 kB 26.2 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_proto-1.28.0-py3-none-any.whl (55 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.8/55.8 kB 25.0 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.5/52.5 kB 23.5 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 220.0/220.0 kB 50.5 MB/s eta 0:00:00\n",
      "Collecting h11>=0.8 (from uvicorn<1->mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.3/181.3 kB 63.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9)) (4.7.2)\n",
      "Collecting anyio<5,>=3.6.2 (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 113.6/113.6 kB 46.0 MB/s eta 0:00:00\n",
      "Collecting exceptiongroup>=1.0.2 (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow->-r requirements.txt (line 9))\n",
      "Downloading pyasn1-0.6.2-py3-none-any.whl (83 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.4/83.4 kB 34.9 MB/s eta 0:00:00\n",
      "Installing collected packages: SimpleITK, huey, werkzeug, typing-extensions, triton, tensorboard-data-server, sqlparse, smmap, sentry-sdk, python-dotenv, pyasn1, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, natsort, markdown, Mako, itsdangerous, importlib-resources, h11, gunicorn, graphql-core, cffi, cachetools, blinker, annotated-types, annotated-doc, absl-py, uvicorn, typing-inspection, sqlalchemy, pydantic-core, pyasn1-modules, opentelemetry-proto, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nibabel, grpcio, graphql-relay, gitdb, Flask, exceptiongroup, docker, cryptography, tensorboard, pydantic, opentelemetry-semantic-conventions, nvidia-cusolver-cu12, graphene, google-auth, gitpython, Flask-CORS, anyio, alembic, wandb, torch, starlette, opentelemetry-sdk, databricks-sdk, monai, mlflow-tracing, fastapi, mlflow-skinny, mlflow\n",
      "Attempting uninstall: werkzeug\n",
      "Found existing installation: Werkzeug 2.3.6\n",
      "Uninstalling Werkzeug-2.3.6:\n",
      "Successfully uninstalled Werkzeug-2.3.6\n",
      "Attempting uninstall: typing-extensions\n",
      "Found existing installation: typing_extensions 4.7.1\n",
      "Uninstalling typing_extensions-4.7.1:\n",
      "Successfully uninstalled typing_extensions-4.7.1\n",
      "Attempting uninstall: triton\n",
      "Found existing installation: triton 2.0.0.dev20221202\n",
      "Uninstalling triton-2.0.0.dev20221202:\n",
      "Successfully uninstalled triton-2.0.0.dev20221202\n",
      "Attempting uninstall: pyasn1\n",
      "Found existing installation: pyasn1 0.4.8\n",
      "Uninstalling pyasn1-0.4.8:\n",
      "Successfully uninstalled pyasn1-0.4.8\n",
      "Attempting uninstall: protobuf\n",
      "Found existing installation: protobuf 3.20.3\n",
      "Uninstalling protobuf-3.20.3:\n",
      "Successfully uninstalled protobuf-3.20.3\n",
      "Attempting uninstall: numpy\n",
      "Found existing installation: numpy 1.24.4\n",
      "Uninstalling numpy-1.24.4:\n",
      "Successfully uninstalled numpy-1.24.4\n",
      "Attempting uninstall: cffi\n",
      "Found existing installation: cffi 1.15.1\n",
      "Uninstalling cffi-1.15.1:\n",
      "Successfully uninstalled cffi-1.15.1\n",
      "Attempting uninstall: cryptography\n",
      "Found existing installation: cryptography 41.0.2\n",
      "Uninstalling cryptography-41.0.2:\n",
      "Successfully uninstalled cryptography-41.0.2\n",
      "Attempting uninstall: pydantic\n",
      "Found existing installation: pydantic 1.10.11\n",
      "Uninstalling pydantic-1.10.11:\n",
      "Successfully uninstalled pydantic-1.10.11\n",
      "Attempting uninstall: torch\n",
      "Found existing installation: torch 2.0.0\n",
      "Uninstalling torch-2.0.0:\n",
      "Successfully uninstalled torch-2.0.0\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "confection 0.1.0 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.12.5 which is incompatible.\n",
      "fastai 2.7.12 requires torch<2.1,>=1.7, but you have torch 2.4.1 which is incompatible.\n",
      "numba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.\n",
      "pyopenssl 23.2.0 requires cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0, but you have cryptography 46.0.3 which is incompatible.\n",
      "sagemaker-training 4.6.1 requires protobuf<=3.20.3,>=3.9.2, but you have protobuf 4.25.8 which is incompatible.\n",
      "smdebug 1.0.34 requires protobuf<=3.20.3,>=3.20.0, but you have protobuf 4.25.8 which is incompatible.\n",
      "spacy 3.6.0 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.12.5 which is incompatible.\n",
      "thinc 8.1.10 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.12.5 which is incompatible.\n",
      "Successfully installed Flask-3.1.2 Flask-CORS-6.0.2 Mako-1.3.10 SimpleITK-2.5.3 absl-py-2.3.1 alembic-1.18.1 annotated-doc-0.0.4 annotated-types-0.7.0 anyio-4.12.1 blinker-1.9.0 cachetools-6.2.5 cffi-2.0.0 cryptography-46.0.3 databricks-sdk-0.80.0 docker-7.1.0 exceptiongroup-1.3.1 fastapi-0.128.0 gitdb-4.0.12 gitpython-3.1.46 google-auth-2.47.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 grpcio-1.76.0 gunicorn-23.0.0 h11-0.16.0 huey-2.6.0 importlib-resources-6.5.2 itsdangerous-2.2.0 markdown-3.10.1 mlflow-3.8.1 mlflow-skinny-3.8.1 mlflow-tracing-3.8.1 monai-1.3.2 natsort-8.4.0 nibabel-5.3.3 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 opentelemetry-api-1.39.1 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 protobuf-4.25.8 pyasn1-0.6.2 pyasn1-modules-0.4.2 pydantic-2.12.5 pydantic-core-2.41.5 python-dotenv-1.2.1 sentry-sdk-2.50.0 smmap-5.0.2 sqlalchemy-2.0.46 sqlparse-0.5.5 starlette-0.50.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 torch-2.4.1 triton-3.0.0 typing-extensions-4.15.0 typing-inspection-0.4.2 uvicorn-0.40.0 wandb-0.24.0 werkzeug-3.1.5\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.3\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2026-01-25 20:52:53,474 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2026-01-25 20:52:53,474 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2026-01-25 20:52:53,531 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2026-01-25 20:52:53,576 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2026-01-25 20:52:53,585 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\n",
      "2026-01-25 20:52:53,585 sagemaker-training-toolkit INFO     Creating SSH daemon.\n",
      "2026-01-25 20:52:53,585 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\n",
      "2026-01-25 20:52:53,585 sagemaker-training-toolkit INFO     Network interface name: eth0\n",
      "2026-01-25 20:52:53,585 sagemaker-training-toolkit INFO     Host: ['algo-1']\n",
      "2026-01-25 20:52:53,586 sagemaker-training-toolkit INFO     instance type: ml.g4dn.12xlarge\n",
      "2026-01-25 20:52:53,586 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1'] Hosts: ['algo-1'] process_per_hosts: 4 num_processes: 4\n",
      "2026-01-25 20:52:53,621 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2026-01-25 20:52:53,631 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_instance_type\": \"ml.g4dn.12xlarge\",\n",
      "        \"sagemaker_pytorch_ddp_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.12xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 2,\n",
      "        \"epochs\": 10,\n",
      "        \"lr\": 0.0001,\n",
      "        \"model_name\": \"SegResNet\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.12xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"pytorch-training-2026-01-25-20-44-53-697\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-575108919340/pytorch-training-2026-01-25-20-44-53-697/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_fsdp\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 48,\n",
      "    \"num_gpus\": 4,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.12xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.12xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"train_fsdp.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"batch_size\":2,\"epochs\":10,\"lr\":0.0001,\"model_name\":\"SegResNet\"}\n",
      "SM_USER_ENTRY_POINT=train_fsdp.py\n",
      "SM_FRAMEWORK_PARAMS={\"sagemaker_instance_type\":\"ml.g4dn.12xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.12xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\n",
      "SM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"training\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g4dn.12xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.12xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=train_fsdp\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=48\n",
      "SM_NUM_GPUS=4\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-575108919340/pytorch-training-2026-01-25-20-44-53-697/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.g4dn.12xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.12xlarge\",\"distribution_hosts\":[\"algo-1\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":2,\"epochs\":10,\"lr\":0.0001,\"model_name\":\"SegResNet\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.12xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"pytorch-training-2026-01-25-20-44-53-697\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-575108919340/pytorch-training-2026-01-25-20-44-53-697/source/sourcedir.tar.gz\",\"module_name\":\"train_fsdp\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":4,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.12xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"train_fsdp.py\"}\n",
      "SM_USER_ARGS=[\"--batch_size\",\"2\",\"--epochs\",\"10\",\"--lr\",\"0.0001\",\"--model_name\",\"SegResNet\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "SM_HP_BATCH_SIZE=2\n",
      "SM_HP_EPOCHS=10\n",
      "SM_HP_LR=0.0001\n",
      "SM_HP_MODEL_NAME=SegResNet\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\n",
      "Invoking script with the following command:\n",
      "mpirun --host algo-1 -np 4 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 1 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_SINGLENODE=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.10/site-packages/gethostname.cpython-310-x86_64-linux-gnu.so -x NCCL_PROTO=simple smddprun /opt/conda/bin/python3.10 -m mpi4py train_fsdp.py --batch_size 2 --epochs 10 --lr 0.0001 --model_name SegResNet\n",
      "[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "[1,mpirank:1,algo-1]<stderr>:/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "[1,mpirank:1,algo-1]<stderr>:  warn(\n",
      "[1,mpirank:2,algo-1]<stderr>:/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "[1,mpirank:2,algo-1]<stderr>:  warn(\n",
      "[1,mpirank:3,algo-1]<stderr>:/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "[1,mpirank:3,algo-1]<stderr>:  warn(\n",
      "[1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "[1,mpirank:0,algo-1]<stderr>:  warn(\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Starting FSDP training with 4 GPUs\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Training SegResNet with FSDP\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:World size: 4\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Hyperparameters: LR=0.0001, Batch Size=2, Epochs=10\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Training samples: 20, Validation samples: 10\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Model wrapped with FSDP\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:\\n==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 1/10\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:164 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:164 [0] NCCL INFO Bootstrap : Using eth0:10.2.209.99<0>\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:164 [0] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v8 symbol.\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:164 [0] NCCL INFO NET/Plugin: Loaded net plugin AWS Libfabric (v6)\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:164 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:164 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:164 [0] NCCL INFO cudaDriverVersion 12080\n",
      "[1,mpirank:0,algo-1]<stdout>:NCCL version 2.20.5+cuda12.4\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO NET/OFI Forcing AWS OFI ndev 2\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO NET/OFI Selected Provider is efa\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:1b.0 path /sys/devices/pci0000:00/\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO Using non-device net plugin version 0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO Using network AWS Libfabric\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:156 [2] NCCL INFO cudaDriverVersion 12080\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:156 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:156 [2] NCCL INFO Bootstrap : Using eth0:10.2.209.99<0>\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:156 [2] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v8 symbol.\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:156 [2] NCCL INFO NET/Plugin: Loaded net plugin AWS Libfabric (v6)\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:156 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:156 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO NET/OFI Forcing AWS OFI ndev 2\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO NET/OFI Selected Provider is efa\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:1b.0 path /sys/devices/pci0000:00\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO Using non-device net plugin version 0\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO Using network AWS Libfabric\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:154 [1] NCCL INFO cudaDriverVersion 12080\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:154 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:154 [1] NCCL INFO Bootstrap : Using eth0:10.2.209.99<0>\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:154 [1] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v8 symbol.\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:154 [1] NCCL INFO NET/Plugin: Loaded net plugin AWS Libfabric (v6)\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:154 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:154 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:160 [3] NCCL INFO cudaDriverVersion 12080\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:160 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:160 [3] NCCL INFO Bootstrap : Using eth0:10.2.209.99<0>\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:160 [3] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v8 symbol.\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:160 [3] NCCL INFO NET/Plugin: Loaded net plugin AWS Libfabric (v6)\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:160 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:160 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO NET/OFI Forcing AWS OFI ndev 2\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO NET/OFI Selected Provider is efa\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:1b.0 path /sys/devices/pci0000:00/\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO Using non-device net plugin version 0\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO Using network AWS Libfabric\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO NET/OFI Forcing AWS OFI ndev 2\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO NET/OFI Selected Provider is efa\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:1b.0 path /sys/devices/pci0000:00\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO Using non-device net plugin version 0\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO Using network AWS Libfabric\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO comm 0x55f4e05d7370 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 1d0 commId 0x9851065a24234a88 - Init START\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO comm 0x55fba704c0f0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1b0 commId 0x9851065a24234a88 - Init START\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO comm 0x55f88c952010 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 1c0 commId 0x9851065a24234a88 - Init START\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO comm 0x55febf8dca60 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId 1e0 commId 0x9851065a24234a88 - Init START\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:1b.0 path /sys/devices/pci0000:00\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:1c.0 path /sys/devices/pci0000:00/\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:1b.0 path /sys/devices/pci0000:00\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:1c.0 path /sys/devices/pci0000:00/\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:1b.0 path /sys/devices/pci0000:00/\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:1b.0 path /sys/devices/pci0000:00/\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:1c.0 path /sys/devices/pci0000:00\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:1c.0 path /sys/devices/pci0000:00\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO NVLS multicast support is not available on dev 2\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO NVLS multicast support is not available on dev 3\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO NVLS multicast support is not available on dev 1\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO NVLS multicast support is not available on dev 0\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO comm 0x55febf8dca60 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO comm 0x55f88c952010 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO comm 0x55fba704c0f0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO P2P Chunksize set to 131072\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO comm 0x55f4e05d7370 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO Channel 00/02 :    0   1   2   3\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO Channel 01/02 :    0   1   2   3\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO P2P Chunksize set to 131072\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO P2P Chunksize set to 131072\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO P2P Chunksize set to 131072\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO Channel 00 : 3[3] -> 0[0] via SHM/direct/direct\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO Channel 01 : 3[3] -> 0[0] via SHM/direct/direct\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO Channel 00 : 0[0] -> 1[1] via SHM/direct/direct\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO Channel 01 : 0[0] -> 1[1] via SHM/direct/direct\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO Channel 00 : 2[2] -> 3[3] via SHM/direct/direct\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO Channel 01 : 2[2] -> 3[3] via SHM/direct/direct\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO Channel 00 : 1[1] -> 2[2] via SHM/direct/direct\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO Channel 01 : 1[1] -> 2[2] via SHM/direct/direct\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO Connected all rings\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO Connected all rings\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO Connected all rings\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO Connected all rings\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO Channel 00 : 3[3] -> 2[2] via SHM/direct/direct\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO Channel 01 : 3[3] -> 2[2] via SHM/direct/direct\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO Channel 00 : 1[1] -> 0[0] via SHM/direct/direct\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO Channel 01 : 1[1] -> 0[0] via SHM/direct/direct\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO Channel 00 : 2[2] -> 1[1] via SHM/direct/direct\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO Channel 01 : 2[2] -> 1[1] via SHM/direct/direct\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO Connected all trees\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO NCCL_PROTO set by environment to simple\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO Connected all trees\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO 2 coll channels, 0 collnet channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO NCCL_PROTO set by environment to simple\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO Connected all trees\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO NCCL_PROTO set by environment to simple\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO 2 coll channels, 0 collnet channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO 2 coll channels, 0 collnet channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO Connected all trees\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO NCCL_PROTO set by environment to simple\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO 2 coll channels, 0 collnet channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1491 [3] NCCL INFO comm 0x55febf8dca60 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId 1e0 commId 0x9851065a24234a88 - Init COMPLETE\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1474 [0] NCCL INFO comm 0x55fba704c0f0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1b0 commId 0x9851065a24234a88 - Init COMPLETE\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1479 [2] NCCL INFO comm 0x55f4e05d7370 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 1d0 commId 0x9851065a24234a88 - Init COMPLETE\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1488 [1] NCCL INFO comm 0x55f88c952010 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 1c0 commId 0x9851065a24234a88 - Init COMPLETE\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 1:  33%|███▎      | 1/3 [00:15<00:30, 15.07s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 1:  67%|██████▋   | 2/3 [00:15<00:06,  6.63s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 1: 100%|██████████| 3/3 [00:16<00:00,  3.83s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 1: 100%|██████████| 3/3 [00:16<00:00,  5.44s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 1 - Average Loss: 0.5976\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:\\n==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 2/10\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 2:  33%|███▎      | 1/3 [00:14<00:28, 14.29s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 2:  67%|██████▋   | 2/3 [00:15<00:06,  6.31s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 2: 100%|██████████| 3/3 [00:15<00:00,  3.66s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 2: 100%|██████████| 3/3 [00:15<00:00,  5.18s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 2 - Average Loss: 0.5970\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Validation:  50%|█████     | 1/2 [00:15<00:15, 15.47s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Validation: 100%|██████████| 2/2 [00:15<00:00,  7.79s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Validation Dice: 0.0034\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:New best model saved! Dice: 0.0034\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:\\n==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 3/10\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 3:  33%|███▎      | 1/3 [00:14<00:28, 14.39s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 3:  67%|██████▋   | 2/3 [00:15<00:06,  6.35s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 3: 100%|██████████| 3/3 [00:15<00:00,  3.68s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 3: 100%|██████████| 3/3 [00:15<00:00,  5.22s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 3 - Average Loss: 0.5967\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:\\n==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 4/10\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 4:  33%|███▎      | 1/3 [00:14<00:28, 14.43s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 4:  67%|██████▋   | 2/3 [00:15<00:06,  6.37s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 4: 100%|██████████| 3/3 [00:15<00:00,  3.69s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 4: 100%|██████████| 3/3 [00:15<00:00,  5.23s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 4 - Average Loss: 0.5964\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Validation:  50%|█████     | 1/2 [00:15<00:15, 15.36s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Validation: 100%|██████████| 2/2 [00:15<00:00,  7.74s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Validation Dice: 0.0054\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:New best model saved! Dice: 0.0054\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:\\n==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 5/10\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 5:  33%|███▎      | 1/3 [00:14<00:28, 14.38s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 5:  67%|██████▋   | 2/3 [00:15<00:06,  6.35s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 5: 100%|██████████| 3/3 [00:15<00:00,  3.68s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 5: 100%|██████████| 3/3 [00:15<00:00,  5.22s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 5 - Average Loss: 0.5960\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:\\n==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 6/10\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 6:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 6:  33%|███▎      | 1/3 [00:14<00:29, 14.51s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 6:  67%|██████▋   | 2/3 [00:15<00:06,  6.40s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 6: 100%|██████████| 3/3 [00:15<00:00,  3.70s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 6: 100%|██████████| 3/3 [00:15<00:00,  5.26s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 6 - Average Loss: 0.5958\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Validation:  50%|█████     | 1/2 [00:15<00:15, 15.37s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Validation: 100%|██████████| 2/2 [00:15<00:00,  7.74s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Validation Dice: 0.0074\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:New best model saved! Dice: 0.0074\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:\\n==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 7/10\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 7:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 7:  33%|███▎      | 1/3 [00:13<00:26, 13.25s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 7:  67%|██████▋   | 2/3 [00:14<00:06,  6.10s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 7: 100%|██████████| 3/3 [00:14<00:00,  3.54s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 7: 100%|██████████| 3/3 [00:14<00:00,  4.96s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 7 - Average Loss: 0.5955\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:\\n==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 8/10\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 8:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 8:  33%|███▎      | 1/3 [00:14<00:28, 14.45s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 8:  67%|██████▋   | 2/3 [00:15<00:06,  6.38s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 8: 100%|██████████| 3/3 [00:15<00:00,  3.70s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 8: 100%|██████████| 3/3 [00:15<00:00,  5.24s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 8 - Average Loss: 0.5951\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Validation:  50%|█████     | 1/2 [00:15<00:15, 15.37s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Validation: 100%|██████████| 2/2 [00:15<00:00,  7.74s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Validation Dice: 0.0071\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:\\n==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 9/10\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 9:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 9:  33%|███▎      | 1/3 [00:14<00:28, 14.33s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 9:  67%|██████▋   | 2/3 [00:15<00:06,  6.33s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 9: 100%|██████████| 3/3 [00:15<00:00,  3.67s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 9: 100%|██████████| 3/3 [00:15<00:00,  5.20s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 9 - Average Loss: 0.5951\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:\\n==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 10/10\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:==================================================\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 10:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 10:  33%|███▎      | 1/3 [00:14<00:28, 14.39s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 10:  67%|██████▋   | 2/3 [00:15<00:06,  6.36s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 10: 100%|██████████| 3/3 [00:15<00:00,  3.68s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Epoch 10: 100%|██████████| 3/3 [00:15<00:00,  5.22s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Epoch 10 - Average Loss: 0.5950\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Validation:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Validation:  50%|█████     | 1/2 [00:15<00:15, 15.35s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015Rank 0 - Validation: 100%|██████████| 2/2 [00:15<00:00,  7.73s/it]\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:1494 [1] NCCL INFO [Service thread] Connection closed by localRank 1\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:1492 [3] NCCL INFO [Service thread] Connection closed by localRank 3\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Validation Dice: 0.0096\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:1495 [2] NCCL INFO [Service thread] Connection closed by localRank 2\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:New best model saved! Dice: 0.0096\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:\\nTraining completed!\n",
      "[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Best Dice: 0.0096 at epoch 10\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:1493 [0] NCCL INFO [Service thread] Connection closed by localRank 0\n",
      "[1,mpirank:3,algo-1]<stdout>:algo-1:160:2385 [3] NCCL INFO comm 0x55febf8dca60 rank 3 nranks 4 cudaDev 3 busId 1e0 - Abort COMPLETE\n",
      "[1,mpirank:2,algo-1]<stdout>:algo-1:156:2386 [2] NCCL INFO comm 0x55f4e05d7370 rank 2 nranks 4 cudaDev 2 busId 1d0 - Abort COMPLETE\n",
      "[1,mpirank:1,algo-1]<stdout>:algo-1:154:2384 [1] NCCL INFO comm 0x55f88c952010 rank 1 nranks 4 cudaDev 1 busId 1c0 - Abort COMPLETE\n",
      "[1,mpirank:0,algo-1]<stdout>:algo-1:164:2387 [0] NCCL INFO comm 0x55fba704c0f0 rank 0 nranks 4 cudaDev 0 busId 1b0 - Abort COMPLETE\n",
      "2026-01-25 20:56:56,928 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2026-01-25 20:56:56,928 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2026-01-25 20:56:56,928 sagemaker-training-toolkit INFO     Begin writing status file from leader node to worker nodes\n",
      "\n",
      "2026-01-25 20:57:31 Uploading - Uploading generated training model2026-01-25 20:57:26,940 sagemaker-training-toolkit INFO     Finished writing status file from leader node to worker nodes\n",
      "2026-01-25 20:57:26,940 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2026-01-25 20:57:44 Completed - Instances not retained as a result of warmpool resource limits being exceeded\n",
      "Training seconds: 687\n",
      "Billable seconds: 687\n"
     ]
    }
   ],
   "source": [
    "# Start training job\n",
    "estimator.fit({'training': data_path}, wait=True, logs='All')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model artifacts: s3://sagemaker-us-east-1-575108919340/pytorch-training-2026-01-25-20-44-53-697/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Model artifacts location\n",
    "model_data = estimator.model_data\n",
    "print(f\"Model artifacts: {model_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Metrics\n",
    "\n",
    "View training metrics in CloudWatch or download TensorBoard logs from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job: pytorch-training-2026-01-25-20-44-53-697\n",
      "\n",
      "CloudWatch logs:\n",
      "https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logsV2:log-groups/log-group/$252Faws$252Fsagemaker$252FTrainingJobs\n"
     ]
    }
   ],
   "source": [
    "# Get training job name\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "print(f\"Training job: {training_job_name}\")\n",
    "\n",
    "# CloudWatch logs\n",
    "print(f\"\\nCloudWatch logs:\")\n",
    "print(f\"https://console.aws.amazon.com/cloudwatch/home?region={region}#logsV2:log-groups/log-group/$252Faws$252Fsagemaker$252FTrainingJobs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg-jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
