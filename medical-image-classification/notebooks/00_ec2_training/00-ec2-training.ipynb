{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EC2 Training Tutorial: Medical Image Classification\n",
    "\n",
    "Train DenseNet121 or ViT models on medical images using MONAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "Import libraries and configure logging. Check GPU availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import monai\n",
    "from monai.data import DataLoader\n",
    "from monai.networks.nets import DenseNet121, ViT\n",
    "from monai.transforms import Compose, LoadImage, EnsureChannelFirst, Resize, ScaleIntensity\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from PIL import ImageFile\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Logging\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = os.path.join(os.getcwd(), 'logs', 'log_' + timestamp)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s',\n",
    "                   handlers=[logging.FileHandler(os.path.join(log_dir, 'app.log')),\n",
    "                            logging.StreamHandler(sys.stdout)])\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configure Training\n",
    "\n",
    "Set data paths and hyperparameters. Choose DenseNet121 or ViT architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths Change these paths as needed\n",
    "data_dir = '/home/ubuntu/data/vindr-spinexr-subset'\n",
    "model_dir = '/home/ubuntu/data/spine-model'\n",
    "output_dir = '/home/ubuntu/data/spine-output'\n",
    "\n",
    "# Hyperparameters\n",
    "model_name = 'DenseNet121'  # or 'ViT'\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "num_epochs = 3\n",
    "val_interval = 10\n",
    "early_stopping_rounds = 10\n",
    "img_size = (256, 256, 1)\n",
    "\n",
    "os.makedirs(os.path.join(model_dir, model_name), exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Model\n",
    "\n",
    "Create ModelDef class to instantiate DenseNet121 or ViT from MONAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelDef:\n",
    "    def __init__(self, num_classes, model_name):\n",
    "        self.num_classes = num_classes\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def get_model(self):\n",
    "        if self.model_name == \"DenseNet121\":\n",
    "            return DenseNet121(spatial_dims=2, in_channels=1, out_channels=self.num_classes)\n",
    "        elif self.model_name == \"ViT\":\n",
    "            return ViT(in_channels=1, img_size=(256, 256, 1), patch_size=(16, 16, 1),\n",
    "                      hidden_size=768, mlp_dim=3072, num_layers=12, num_heads=12,\n",
    "                      classification=True, num_classes=self.num_classes)\n",
    "        else:\n",
    "            raise ValueError(f\"Model {self.model_name} not supported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Dataset & Loaders\n",
    "\n",
    "Build custom dataset from label_dict.json. Apply MONAI transforms and create data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "\n",
    "def generate_list_labels(data_folder):\n",
    "    with open(\"../../ec2/label_dict.json\", \"r\") as fid:\n",
    "        label_dict = json.load(fid)\n",
    "    \n",
    "    image_list, label_list = [], []\n",
    "    for _label in label_dict:\n",
    "        label_data = os.path.join(data_folder, _label)\n",
    "        if not os.path.exists(label_data):\n",
    "            continue\n",
    "        for _file in os.listdir(label_data):\n",
    "            image_list.append(os.path.join(label_data, _file))\n",
    "            label_list.append(label_dict[_label])\n",
    "\n",
    "    c = list(zip(image_list, label_list))\n",
    "    random.shuffle(c)\n",
    "    image_list, label_list = zip(*c)\n",
    "    return image_list, label_list, len(label_dict)\n",
    "\n",
    "\n",
    "def create_data_loaders(data, batch_size):\n",
    "    transforms = Compose([LoadImage(), EnsureChannelFirst(), \n",
    "                         Resize(spatial_size=img_size), ScaleIntensity()])\n",
    "    \n",
    "    train_img, train_lbl, num_classes = generate_list_labels(os.path.join(data, 'train'))\n",
    "    val_img, val_lbl, _ = generate_list_labels(os.path.join(data, 'valid'))\n",
    "    test_img, test_lbl, _ = generate_list_labels(os.path.join(data, 'test'))\n",
    "\n",
    "    train_ds = MedNISTDataset(train_img, train_lbl, transforms)\n",
    "    val_ds = MedNISTDataset(val_img, val_lbl, transforms)\n",
    "    test_ds = MedNISTDataset(test_img, test_lbl, transforms)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "    \n",
    "    return train_loader, test_loader, val_loader, num_classes\n",
    "\n",
    "\n",
    "train_loader, test_loader, validation_loader, num_classes = create_data_loaders(data_dir, batch_size)\n",
    "logger.info(f'Classes: {num_classes}, Train: {len(train_loader.dataset)}, Val: {len(validation_loader.dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Define Training Functions\n",
    "\n",
    "Implement test() for validation and train() with early stopping and TensorBoard logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion, device, model_name):\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Validation\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            if model_name == 'DenseNet121':\n",
    "                outputs = model(inputs[:, :, :, :, 0])\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs[0], labels)\n",
    "                _, preds = torch.max(outputs[0], 1)\n",
    "                \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "    total_loss = running_loss / len(test_loader.dataset)\n",
    "    total_acc = running_corrects / len(test_loader.dataset)\n",
    "    logger.info(f\"Val Loss: {total_loss:.4f}, Val Acc: {total_acc:.4f}\")\n",
    "    return total_loss, total_acc\n",
    "\n",
    "\n",
    "def train(model, train_loader, validation_loader, criterion, optimizer, device, \n",
    "          model_name, num_epochs, val_interval, early_stopping_rounds, model_dir, output_dir):\n",
    "    best_loss = 1e6\n",
    "    loss_counter = 0\n",
    "    writer = SummaryWriter(log_dir=os.path.join(output_dir, model_name, 'logs'))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, running_corrects, running_samples = 0.0, 0, 0\n",
    "        print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
    "\n",
    "        for step, (inputs, labels) in enumerate(tqdm(train_loader)):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            if model_name == 'DenseNet121':\n",
    "                outputs = model(inputs[:, :, :, :, 0])\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs[0], labels)\n",
    "                _, preds = torch.max(outputs[0], 1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data).item()\n",
    "            running_samples += len(inputs)\n",
    "            \n",
    "            if running_samples % 4000 == 0:\n",
    "                accuracy = running_corrects / running_samples\n",
    "                logger.info(f\"[{running_samples}/{len(train_loader.dataset)}] Loss: {loss.item():.2f}, Acc: {accuracy:.4f}\")\n",
    "                writer.add_scalar('train/accuracy', accuracy, epoch * len(train_loader) + step)\n",
    "\n",
    "            writer.add_scalar('train/loss', loss.item(), epoch * len(train_loader) + step)\n",
    "            \n",
    "        epoch_loss = running_loss / running_samples\n",
    "        epoch_acc = running_corrects / running_samples\n",
    "\n",
    "        if epoch % val_interval == 0:\n",
    "            model.eval()\n",
    "            val_loss, val_acc = test(model, validation_loader, criterion, device, model_name)\n",
    "            \n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), os.path.join(model_dir, model_name, f'best_model_{epoch}.pth'))\n",
    "                logger.info(f\"âœ“ Saved best model (loss: {best_loss:.4f})\")\n",
    "            else:\n",
    "                loss_counter += 1\n",
    "                \n",
    "            logger.info(f'Epoch {epoch}: Train Loss={epoch_loss:.4f}, Train Acc={epoch_acc:.4f}, Val Loss={val_loss:.4f}')\n",
    "            writer.add_scalar('val/loss', val_loss, epoch)\n",
    "            writer.add_scalar('val/accuracy', val_acc, epoch)\n",
    "            \n",
    "        if loss_counter == early_stopping_rounds:\n",
    "            logger.info('Early stopping triggered')\n",
    "            break\n",
    "            \n",
    "    writer.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train Model\n",
    "\n",
    "Initialize model, optimizer, and loss function. Run training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "model = ModelDef(num_classes, model_name).get_model().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "logger.info(f\"Starting training: {model_name} with {num_classes} classes\")\n",
    "\n",
    "# Train\n",
    "model = train(model, train_loader, validation_loader, criterion, optimizer, device,\n",
    "             model_name, num_epochs, val_interval, early_stopping_rounds, model_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save Model\n",
    "\n",
    "Save final trained model weights to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.join(output_dir, model_name)\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "torch.save(model.state_dict(), os.path.join(out_dir, \"model.pth\"))\n",
    "logger.info(f\"Model saved to {os.path.join(out_dir, 'model.pth')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View TensorBoard\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir=./logs\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop_singleGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
